# Configuración de Ollama
# Desde devcontainer, usar host.docker.internal para acceder al host
# Desde host local, usar localhost
# OLLAMA_HOST=http://host.docker.internal:11434
OLLAMA_HOST=http://172.17.0.1:11434
# Modelo a usar
# OLLAMA_MODEL=llama3.2:latest
# OLLAMA_MODEL=mistral
OLLAMA_MODEL=qwen3:4b
# Temperatura del modelo (0.0 = determinístico, 1.0 = creativo)
OLLAMA_TEMPERATURE=0.7



# Configuración de Neo4j
NEO4J_URI=neo4j://172.17.0.1:7687
NEO4J_USER=neo4j
NEO4J_PASS=password

OPENAI_BASE_URL=http://172.17.0.1:11434
OPENAI_API_KEY=ollama